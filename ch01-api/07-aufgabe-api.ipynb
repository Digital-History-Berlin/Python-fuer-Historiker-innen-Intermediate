{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(aufgabe-api)=\n",
    "\n",
    "# üìù √úbung zum Aufbereiten von API-Daten\n",
    "\n",
    "**Zum [L√∂sungsnotebook](api-loesung)**\n",
    "\n",
    "In diesem √úbung geht es um das Laden von Daten von einer API sowie um die erste strukturierte Aufbereitung dieser Daten f√ºr nachfolgende Auswertungsans√§tze. Wir werden mit dem Beispiel aus [Einf√ºhrung in Web APIs](intro-api) weitermachen.\n",
    "\n",
    "Diesmal ist es nicht die Aufgabe, Code zu schreiben, sondern die Herausforderunge besteht darin, fremden Code zu lesen.\n",
    "\n",
    "## Aufgabe: API-Daten abfragen, abrufen, aufbereiten\n",
    "\n",
    "- Lesen und verstehen Sie den folgenden Code. \n",
    "\n",
    "- Erg√§nzen Sie die doc-Strings\n",
    "\n",
    "- Kommentieren Sie ggf. Inline die Code-Zeile, wenn Sie dies f√ºr das Verst√§ndnis f√ºr n√∂tig halten.\n",
    "\n",
    "- Nutzen Sie Markdown-Zellen, um Teile des Codes an den Stellen, wo es n√∂tig erscheint, genauer zu erl√§utern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import urllib.parse\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helferfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_europeana_search_api(base_url, apikey, params):\n",
    "    '''\n",
    "    DOC-STRING\n",
    "    '''\n",
    "\n",
    "    api_search_url = base_url + \\\n",
    "                      'query=' + params['query'] + \\\n",
    "                      '&qf=LANGUAGE:' + params['language'] + \\\n",
    "                      '&profile=' + params['profile'] + \\\n",
    "                      '&hit.selectors=' + params['hit.selectors'] + \\\n",
    "                      '&sort=' + params['sort'] + \\\n",
    "                      '&rows=' + params['rows'] + \\\n",
    "                      '&cursor=' + params['cursor'] + \\\n",
    "                      '&wskey='+apikey\n",
    "    \n",
    "    response = requests.get(api_search_url)\n",
    "    response_content = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      print('response status ok')\n",
    "      print(response_content['params']) \n",
    "    else:\n",
    "      print(response_content['error'] + '\\n' + response_content['code']) \n",
    "\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_total(base_url, apikey, params):\n",
    "    '''\n",
    "    DOC-STRING\n",
    "    '''\n",
    "\n",
    "    cursor = True\n",
    "    results_items_list = [] \n",
    "    results_hits_list = [] \n",
    "\n",
    "    while cursor == True:\n",
    "        results = get_data_from_europeana_search_api(base_url, apikey, params)\n",
    "        if 'nextCursor' in results:\n",
    "            params['cursor'] = urllib.parse.quote(results['nextCursor']) \n",
    "            results_items_list.extend(results['items'])\n",
    "            results_hits_list.extend(results['hits'])\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            cursor = False\n",
    "            \n",
    "    return results_items_list, results_hits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ids_in_text_file(results_list):\n",
    "    '''\n",
    "    DOC-STRING\n",
    "    '''\n",
    "\n",
    "    with open('europeana_search_result_item_ids.txt', 'a') as prozess_file:\n",
    "        for i in range(0,len(results_list)):\n",
    "            id = results_list[i]['id']\n",
    "            prozess_file.write(id + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_in_csv_file(results_items_list, results_hits_list):\n",
    "    '''\n",
    "    DOC-STRING\n",
    "    '''\n",
    "\n",
    "    with open('newspaper_data.csv', 'w', encoding='utf-8') as csv_file:\n",
    "      header = [\n",
    "                'newspaper title',\n",
    "                'id',\n",
    "                'date',\n",
    "                'data provider',\n",
    "                'hit'\n",
    "                ]\n",
    "      text_writer = csv.DictWriter(csv_file, delimiter = \";\", fieldnames = header)\n",
    "      text_writer.writeheader()\n",
    "\n",
    "      for i in range(0, len(results_items_list)): \n",
    "          title_and_date = results_items_list[i]['title'][0] \n",
    "          date = re.search(r'\\d\\d\\d\\d-\\d\\d-\\d\\d', title_and_date) \n",
    "          title = re.split(r' - \\d\\d\\d\\d-\\d\\d-\\d\\d', title_and_date) \n",
    "          date = date.group()\n",
    "          title = title[0]\n",
    "          hits = [] \n",
    "\n",
    "          for j in range(0, len(results_hits_list)): \n",
    "              if results_hits_list[j]['scope'] == results_items_list[i]['id']: \n",
    "                  selectors = results_hits_list[j]['selectors']\n",
    "                  for sel in range(0, len(selectors)):\n",
    "                      hit_sentence = '' \n",
    "                      if 'prefix' in selectors[sel]: \n",
    "                          hit_sentence += selectors[sel]['prefix']\n",
    "                      if 'exact' in selectors[sel]:\n",
    "                          hit_sentence += selectors[sel]['exact']\n",
    "                      if 'suffix' in selectors[sel]:\n",
    "                          hit_sentence += selectors[sel]['suffix']\n",
    "                      hits.append(hit_sentence)\n",
    "\n",
    "                  new_row = {\n",
    "                            'newspaper title': title,\n",
    "                            'id' : results_items_list[i]['id'],\n",
    "                            'date': date,\n",
    "                            'data provider': results_items_list[i]['dataProvider'][0],\n",
    "                            'hit': hits\n",
    "                            }\n",
    "                  \n",
    "                  text_writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anfrage durchf√ºhren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europeana_search_api_newspaper_url = 'https://newspapers.eanadev.org/api/v2/search.json?'\n",
    "europeana_apikey = # '<YOUR_API_KEY>'\n",
    "\n",
    "europeana_params = {'query':'Pyhton', \n",
    "                    'language':'de', \n",
    "                    'profile':'hits+params', \n",
    "                    'hit.selectors':'5', \n",
    "                    'sort':'europeana_id+desc', \n",
    "                    'rows':'100', \n",
    "                    'cursor':'*'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "europeana_search_request_test = get_data_from_europeana_search_api(europeana_search_api_newspaper_url, \n",
    "                                                                   europeana_apikey, \n",
    "                                                                   europeana_params) \n",
    "if 'totalResults' in europeana_search_request_test:\n",
    "    print(europeana_search_request_test['totalResults'])\n",
    "    \n",
    "europeana_entire_search = get_results_total(europeana_search_api_newspaper_url, \n",
    "                                            europeana_apikey, \n",
    "                                            europeana_params)\n",
    "\n",
    "write_ids_in_text_file(europeana_entire_search[0])\n",
    "write_data_in_csv_file(europeana_entire_search[0], \n",
    "                       europeana_entire_search[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
