{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù √úbung zum Data Mining mit Pandas\n",
    "\n",
    "**Zum [L√∂sungsnotebook](pandas-loesung)**\n",
    "\n",
    "F√ºr die folgenden Aufgaben nutzen wir einen neuen Datensatz. Es handelt sich hier um Reden der Bundesregierung.\n",
    "Die Textdaten f sind dem Projekt German Political Speeches Corpus entnommen. Adrien Barbaresi. (2019). German Political Speeches Corpus (Version v4.2019) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3611246. \n",
    "\n",
    "Barbaresi, Adrien (2018). \"A corpus of German political speeches from the 21st century\", Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), European Language Resources Association (ELRA), pp. 792‚Äì797. http://purl.org/corpus/german-speeches (BibTeX entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Pandas Basics\n",
    "Wir gehen noch mal ein paar grundlegende Befehle durch.\n",
    "\n",
    "1. Importieren Sie die Bibliothek Pandas entsprechend der g√§ngigen Konventionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lesen Sie die Datei `speeches-bundesregierung_bearbeitet.json` im Ordner `data`, der relativ zum √ºbergeordneten Ordner liegt, als Dataframe ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einlesen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lassen Sie sich die ersten und letzten Zeilen des Dataframes anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lassen Sie sich die statistische Beschreibung aller (!) verf√ºgbaren Spalten ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Greifen Sie auf die Zeilen 35 bis 212 in den Spalten \"person\" und \"title\" zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Eigene Datenabfrage gestalten\n",
    "\n",
    "√úberlegen Sie sich f√ºr das Korpus der Reden von Angeh√∂rigen der Bundesregierung eine eigene inhaltlich-thematische Datenabfrage, die von booleschen Masken Gebrauch macht. Ihre Abfrage sollte aus mehreren Bestandteilen bestehen (\"Schlagwortsuche\", Begrenzung nach Redner:in oder Jahr). Gerne k√∂nnen Sie verschiedene logische/boolesche Operatoren miteinander verkn√ºpfen (`&`, `|`, `==`, usw.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielabfrage zur Orientierung\n",
    "mask = (df.loc[:, \"text\"].str.contains(\"Ukraine\")) \\\n",
    "      & (df.loc[:, \"text\"].str.contains(\"Russland\")) \\\n",
    "      & (df.loc[:, \"person\"] == \"Angela Merkel\")        \n",
    "\n",
    "df_uk_ru = df.loc[mask,:]\n",
    "df_uk_ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Anzahl der Token pro Rede ermitteln und speichern\n",
    "\n",
    "Wir wollen die Anzahl der Token, also die L√§nge der einzelnen Reden ermitteln und die Informationen wieder im Dataframe als neue Spalte speichern.\n",
    "\n",
    "- Lesen Sie dazu die Texte aus der Spalte `text` aus und speichern Sie sie in einer Liste. \n",
    "- Sorgen Sie nun daf√ºr, dass die einzelnen Texte in Wortlisten zerlegt werden und bestimmen Sie die L√§nge der einzelnen Wortlisten. \n",
    "- Die L√§nge der Texte soll als neue Spalte `ntokens` zum Dataframe hinzugef√ºgt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Datenabfragen gestalten\n",
    "\n",
    "Erkunden Sie das Korpus von Reden von Angeh√∂rigen der Bundesregierung, um ein tieferes Verst√§ndnis verschiedener thematischer Schwerpunkte und die Nutzung spezifischer Begrifflichkeiten √ºber die Zeit zu gewinnen. \n",
    "\n",
    "1. Extrahieren Sie alle Reden, die im Jahr 2001 gehalten wurden.\n",
    "2. Ermitteln Sie die Anzahl der Reden, die das Wort \"Europa\" enthalten.\n",
    "3. Identifizieren Sie Reden, die den Begriff \"digital\" und \"Digitalisierung\" enthalten. \n",
    "4. Suchen Sie nach Reden, die zwischen 2000 und 2010 gehalten wurden, die sich auf Umweltthemen beziehen. In Frage kommen hierf√ºr Begriffe wie \"Umwelt\", \"Klima\", \"Nachhaltigkeit\" oder √§hnliches. Formulieren Sie eine Abfrage, die mehrere dieser Begriffe ber√ºcksichtigt. Achten Sie ggf. darauf, wie die Bedingungen mit runden Klammern gruppiert werden m√ºssen.\n",
    "\n",
    "Hinweise:\n",
    "- F√ºr diese Aufgabe ben√∂tigen Sie die logischen Operatoren f√ºr *UND* (`&`) und *ODER* (`|`) - letzteres ist je nach Tastatur auf einer anderen Taste. Wichtig: In Python hat der logische Operator `&` eine h√∂here Priorit√§t als `|`. Bei Abfragen, die beide Operatoren verwenden, muss also darauf geachtet werden, wie die Abfragebestandteile mit runden Klammern gruppiert werden.\n",
    "- Die Funktion `contains()` arbeitet standardm√§√üig case-sensitiv. Wenn Sie eine case-insensitive Suche durchf√ºhren m√∂chten, k√∂nnen Sie den Parameter `case=False` erg√§nzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Aufgabe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zweite Aufgabe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dritte Aufgabe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vierte Aufgabe\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mininghistoriansweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
